# Attention: finally getting into attention

for this section tensorflow 1.15 is neccesary

https://www.youtube.com/watch?v=dichIcUZfOw

https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec#d554

positional encoding can be tough to understand: 
https://kazemnejad.com/blog/transformer_architecture_positional_encoding/

Thsi one is in multiple parts: https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452


