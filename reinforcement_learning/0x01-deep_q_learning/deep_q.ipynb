{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_q.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohBNpQtCs589",
        "outputId": "119ae655-c998-49ac-d005-85ea15e612c4"
      },
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve('http://www.atarimania.com/roms/Roms.rar','Roms.rar')\n",
        "!pip install unrar\n",
        "!unrar x Roms.rar\n",
        "!mkdir rars\n",
        "!mv HC\\ ROMS.zip   rars\n",
        "!mv ROMS.zip  rars\n",
        "!python -m atari_py.import_roms rars\n",
        "!pip install keras-rl2\n",
        "!pip install gym\n",
        "!pip install gym[atari]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unrar\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/0b/53130ccd483e3db8c8a460cb579bdb21b458d5494d67a261e1a5b273fbb9/unrar-0.4-py3-none-any.whl\n",
            "Installing collected packages: unrar\n",
            "Successfully installed unrar-0.4\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from Roms.rar\n",
            "\n",
            "Extracting  HC ROMS.zip                                                  \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  ROMS.zip                                                     \b\b\b\b 74%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n",
            "copying adventure.bin from HC ROMS/BY ALPHABET (PAL)/A-G/Adventure (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/adventure.bin\n",
            "copying air_raid.bin from HC ROMS/BY ALPHABET (PAL)/A-G/Air Raid (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/air_raid.bin\n",
            "copying alien.bin from HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Alien.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/alien.bin\n",
            "copying crazy_climber.bin from HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Crazy Climber.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/crazy_climber.bin\n",
            "copying elevator_action.bin from HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Elevator Action (Prototype).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/elevator_action.bin\n",
            "copying gravitar.bin from HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Gravitar.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gravitar.bin\n",
            "copying keystone_kapers.bin from HC ROMS/BY ALPHABET (PAL)/H-R/Keystone Kapers (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/keystone_kapers.bin\n",
            "copying king_kong.bin from HC ROMS/BY ALPHABET (PAL)/H-R/King Kong (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/king_kong.bin\n",
            "copying laser_gates.bin from HC ROMS/BY ALPHABET (PAL)/H-R/Laser Gates (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/laser_gates.bin\n",
            "copying mr_do.bin from HC ROMS/BY ALPHABET (PAL)/H-R/Mr. Do! (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/mr_do.bin\n",
            "copying pacman.bin from HC ROMS/BY ALPHABET (PAL)/H-R/Pac-Man (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pacman.bin\n",
            "copying jamesbond.bin from HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/James Bond 007.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/jamesbond.bin\n",
            "copying koolaid.bin from HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/Kool-Aid Man.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/koolaid.bin\n",
            "copying krull.bin from HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/Krull.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/krull.bin\n",
            "copying montezuma_revenge.bin from HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/Montezuma's Revenge - Featuring Panama Joe.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/montezuma_revenge.bin\n",
            "copying star_gunner.bin from HC ROMS/BY ALPHABET (PAL)/S-Z/REMAINING NTSC ORIGINALS/Stargunner.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/star_gunner.bin\n",
            "copying time_pilot.bin from HC ROMS/BY ALPHABET (PAL)/S-Z/REMAINING NTSC ORIGINALS/Time Pilot.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/time_pilot.bin\n",
            "copying up_n_down.bin from HC ROMS/BY ALPHABET (PAL)/S-Z/REMAINING NTSC ORIGINALS/Up 'n Down.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/up_n_down.bin\n",
            "copying sir_lancelot.bin from HC ROMS/BY ALPHABET (PAL)/S-Z/Sir Lancelot (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/sir_lancelot.bin\n",
            "copying amidar.bin from HC ROMS/BY ALPHABET/A-G/Amidar.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/amidar.bin\n",
            "copying asteroids.bin from HC ROMS/BY ALPHABET/A-G/Asteroids [no copyright].bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asteroids.bin\n",
            "copying atlantis.bin from HC ROMS/BY ALPHABET/A-G/Atlantis.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/atlantis.bin\n",
            "copying bank_heist.bin from HC ROMS/BY ALPHABET/A-G/Bank Heist.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bank_heist.bin\n",
            "copying battle_zone.bin from HC ROMS/BY ALPHABET/A-G/Battlezone.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/battle_zone.bin\n",
            "copying beam_rider.bin from HC ROMS/BY ALPHABET/A-G/Beamrider.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/beam_rider.bin\n",
            "copying berzerk.bin from HC ROMS/BY ALPHABET/A-G/Berzerk.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/berzerk.bin\n",
            "copying bowling.bin from HC ROMS/BY ALPHABET/A-G/Bowling.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bowling.bin\n",
            "copying boxing.bin from HC ROMS/BY ALPHABET/A-G/Boxing.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/boxing.bin\n",
            "copying breakout.bin from HC ROMS/BY ALPHABET/A-G/Breakout - Breakaway IV.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/breakout.bin\n",
            "copying carnival.bin from HC ROMS/BY ALPHABET/A-G/Carnival.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/carnival.bin\n",
            "copying centipede.bin from HC ROMS/BY ALPHABET/A-G/Centipede.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/centipede.bin\n",
            "copying chopper_command.bin from HC ROMS/BY ALPHABET/A-G/Chopper Command.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/chopper_command.bin\n",
            "copying defender.bin from HC ROMS/BY ALPHABET/A-G/Defender.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/defender.bin\n",
            "copying demon_attack.bin from HC ROMS/BY ALPHABET/A-G/Demon Attack.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/demon_attack.bin\n",
            "copying donkey_kong.bin from HC ROMS/BY ALPHABET/A-G/Donkey Kong.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/donkey_kong.bin\n",
            "copying double_dunk.bin from HC ROMS/BY ALPHABET/A-G/Double Dunk.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/double_dunk.bin\n",
            "copying enduro.bin from HC ROMS/BY ALPHABET/A-G/Enduro.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/enduro.bin\n",
            "copying fishing_derby.bin from HC ROMS/BY ALPHABET/A-G/Fishing Derby.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/fishing_derby.bin\n",
            "copying freeway.bin from HC ROMS/BY ALPHABET/A-G/Freeway.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/freeway.bin\n",
            "copying frogger.bin from HC ROMS/BY ALPHABET/A-G/Frogger.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frogger.bin\n",
            "copying frostbite.bin from HC ROMS/BY ALPHABET/A-G/Frostbite.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frostbite.bin\n",
            "copying galaxian.bin from HC ROMS/BY ALPHABET/A-G/Galaxian.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/galaxian.bin\n",
            "copying gopher.bin from HC ROMS/BY ALPHABET/A-G/Gopher.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gopher.bin\n",
            "copying hero.bin from HC ROMS/BY ALPHABET/H-R/H.E.R.O..bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/hero.bin\n",
            "copying ice_hockey.bin from HC ROMS/BY ALPHABET/H-R/Ice Hockey.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ice_hockey.bin\n",
            "copying journey_escape.bin from HC ROMS/BY ALPHABET/H-R/Journey Escape.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/journey_escape.bin\n",
            "copying kaboom.bin from HC ROMS/BY ALPHABET/H-R/Kaboom!.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kaboom.bin\n",
            "copying kangaroo.bin from HC ROMS/BY ALPHABET/H-R/Kangaroo.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kangaroo.bin\n",
            "copying kung_fu_master.bin from HC ROMS/BY ALPHABET/H-R/Kung-Fu Master.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kung_fu_master.bin\n",
            "copying lost_luggage.bin from HC ROMS/BY ALPHABET/H-R/Lost Luggage [no opening scene].bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/lost_luggage.bin\n",
            "copying ms_pacman.bin from HC ROMS/BY ALPHABET/H-R/Ms. Pac-Man.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ms_pacman.bin\n",
            "copying name_this_game.bin from HC ROMS/BY ALPHABET/H-R/Name This Game.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/name_this_game.bin\n",
            "copying phoenix.bin from HC ROMS/BY ALPHABET/H-R/Phoenix.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/phoenix.bin\n",
            "copying pitfall.bin from HC ROMS/BY ALPHABET/H-R/Pitfall! - Pitfall Harry's Jungle Adventure.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pitfall.bin\n",
            "copying pooyan.bin from HC ROMS/BY ALPHABET/H-R/Pooyan.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pooyan.bin\n",
            "copying private_eye.bin from HC ROMS/BY ALPHABET/H-R/Private Eye.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/private_eye.bin\n",
            "copying qbert.bin from HC ROMS/BY ALPHABET/H-R/Q-bert.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/qbert.bin\n",
            "copying riverraid.bin from HC ROMS/BY ALPHABET/H-R/River Raid.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/riverraid.bin\n",
            "copying road_runner.bin from patched version of HC ROMS/BY ALPHABET/H-R/Road Runner.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/road_runner.bin\n",
            "copying robotank.bin from HC ROMS/BY ALPHABET/H-R/Robot Tank.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/robotank.bin\n",
            "copying seaquest.bin from HC ROMS/BY ALPHABET/S-Z/Seaquest.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/seaquest.bin\n",
            "copying skiing.bin from HC ROMS/BY ALPHABET/S-Z/Skiing.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/skiing.bin\n",
            "copying solaris.bin from HC ROMS/BY ALPHABET/S-Z/Solaris.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/solaris.bin\n",
            "copying space_invaders.bin from HC ROMS/BY ALPHABET/S-Z/Space Invaders.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/space_invaders.bin\n",
            "copying surround.bin from HC ROMS/BY ALPHABET/S-Z/Surround - Chase.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/surround.bin\n",
            "copying tennis.bin from HC ROMS/BY ALPHABET/S-Z/Tennis.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tennis.bin\n",
            "copying trondead.bin from HC ROMS/BY ALPHABET/S-Z/TRON - Deadly Discs.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/trondead.bin\n",
            "copying tutankham.bin from HC ROMS/BY ALPHABET/S-Z/Tutankham.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tutankham.bin\n",
            "copying venture.bin from HC ROMS/BY ALPHABET/S-Z/Venture.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/venture.bin\n",
            "copying pong.bin from HC ROMS/BY ALPHABET/S-Z/Video Olympics - Pong Sports.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pong.bin\n",
            "copying video_pinball.bin from HC ROMS/BY ALPHABET/S-Z/Video Pinball - Arcade Pinball.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/video_pinball.bin\n",
            "copying wizard_of_wor.bin from HC ROMS/BY ALPHABET/S-Z/Wizard of Wor.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/wizard_of_wor.bin\n",
            "copying yars_revenge.bin from HC ROMS/BY ALPHABET/S-Z/Yars' Revenge.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/yars_revenge.bin\n",
            "copying zaxxon.bin from HC ROMS/BY ALPHABET/S-Z/Zaxxon.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/zaxxon.bin\n",
            "copying assault.bin from HC ROMS/NTSC VERSIONS OF PAL ORIGINALS/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/assault.bin\n",
            "copying asterix.bin from ROMS/Asterix (AKA Taz) (07-27-1983) (Atari, Jerome Domurat, Steve Woita) (CX2696) (Prototype).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asterix.bin\n",
            "Collecting keras-rl2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/fc/143ee05aed804b3b9052d7b17b13832bc7f3c28e7b1bc50edd09c29d8525/keras_rl2-1.0.5-py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.5.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.19.5)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.34.1)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.12.1)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.5.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.12)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->keras-rl2) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras-rl2) (57.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras-rl2) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras-rl2) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras-rl2) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras-rl2) (1.31.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->keras-rl2) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->keras-rl2) (4.5.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->keras-rl2) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow->keras-rl2) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2) (0.4.8)\n",
            "Installing collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.3.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (0.2.9)\n",
            "Requirement already satisfied: opencv-python; extra == \"atari\" in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (7.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0; extra == \"atari\"->gym[atari]) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vap9SRE0G2yS"
      },
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "import gym\n",
        "import numpy as np\n",
        "# import tensorflow as tf\n",
        "import tensorflow.keras as k\n",
        "# import keras as k\n",
        "# import keras.layers as layers\n",
        "import tensorflow.keras.layers as layers\n",
        "# these only necessary in colab for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1CVn5OBsaRs"
      },
      "source": [
        "# example for displaying game (slow)\n",
        "# import gym\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()\n",
        "# Create a breakout environment\n",
        "# env = gym.make('BreakoutDeterministic-v4')\n",
        "env = gym.make(\"Breakout-v0\")\n",
        "# Reset it, returns the starting frame\n",
        "frame = env.reset()\n",
        "input_shape = env.observation_space.shape\n",
        "prev_screen = env.render(mode='rgb_array')\n",
        "#env.render()\n",
        "plt.imshow(prev_screen)\n",
        "\n",
        "is_done = False\n",
        "while not is_done:\n",
        "  # Perform a random action, returns the new frame, reward and whether the game is over\n",
        "  frame, reward, is_done, _ = env.step(env.action_space.sample())\n",
        "  # Render\n",
        "  screen = env.render(mode='rgb_array')\n",
        "  # uncomment next line to view\n",
        "  # plt.imshow(screen)\n",
        "  ipythondisplay.clear_output(wait=True)\n",
        "  ipythondisplay.display(plt.gcf())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4JW27FCSQFo",
        "outputId": "d8d6ebaf-ac41-490c-8d75-59ddae939c37"
      },
      "source": [
        "env = gym.make(\"Breakout-v0\")\n",
        "num_actions = env.action_space.n\n",
        "state_size = env.observation_space.shape\n",
        "\n",
        "def build_model(state_size, num_actions):\n",
        "    \"\"\" build the keras model for deep learning \"\"\"\n",
        "    # inputs = layers.Input(shape=(84, 84, 4,))\n",
        "    inputs = layers.Input(shape=(4,) + state_size)\n",
        "    layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(inputs)\n",
        "    layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
        "    layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
        "    layer4 = layers.Flatten()(layer3)\n",
        "    layer5 = layers.Dense(512, activation=\"relu\")(layer4)\n",
        "    action = layers.Dense(num_actions, activation=\"linear\")(layer5)\n",
        "    return k.Model(inputs=inputs, outputs=action)\n",
        "\n",
        "model = build_model(state_size, num_actions)\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 4, 210, 160, 3)]  0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 51, 39, 32)     6176      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 24, 18, 64)     32832     \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 4, 22, 16, 64)     36928     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 90112)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               46137856  \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 46,215,844\n",
            "Trainable params: 46,215,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2DNHUxBcj0d",
        "outputId": "a2a88408-ba98-4acb-c930-58910ea7bef5"
      },
      "source": [
        "from rl.agents import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import EpsGreedyQPolicy, LinearAnnealedPolicy\n",
        "from rl.callbacks import FileLogger\n",
        "\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1.,\n",
        "                              value_min=.1, value_test=0.1, nb_steps=1000000)\n",
        "memory = SequentialMemory(limit=1000000, window_length=4)\n",
        "agent = DQNAgent(model=model, policy=policy, nb_actions=num_actions,\n",
        "                 memory=memory, nb_steps_warmup=50000)\n",
        "agent.compile(k.optimizers.Adam(learning_rate=.00025), metrics=['mae'])\n",
        "agent.fit(env, nb_steps=10000, log_interval=1000, visualize=False, verbose=2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 10000 steps ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  170/10000: episode: 1, duration: 8.321s, episode steps: 170, steps per second:  20, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.300 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  367/10000: episode: 2, duration: 8.885s, episode steps: 197, steps per second:  22, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.604 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  760/10000: episode: 3, duration: 16.829s, episode steps: 393, steps per second:  23, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 1.466 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  937/10000: episode: 4, duration: 7.434s, episode steps: 177, steps per second:  24, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.525 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 1109/10000: episode: 5, duration: 7.088s, episode steps: 172, steps per second:  24, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 1380/10000: episode: 6, duration: 11.030s, episode steps: 271, steps per second:  25, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.542 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 1545/10000: episode: 7, duration: 6.659s, episode steps: 165, steps per second:  25, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.576 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 1788/10000: episode: 8, duration: 9.782s, episode steps: 243, steps per second:  25, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 1.453 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 2002/10000: episode: 9, duration: 8.578s, episode steps: 214, steps per second:  25, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.467 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 2277/10000: episode: 10, duration: 10.880s, episode steps: 275, steps per second:  25, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 2488/10000: episode: 11, duration: 8.417s, episode steps: 211, steps per second:  25, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.488 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 2721/10000: episode: 12, duration: 9.236s, episode steps: 233, steps per second:  25, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 1.403 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 2968/10000: episode: 13, duration: 9.881s, episode steps: 247, steps per second:  25, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 1.506 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 3239/10000: episode: 14, duration: 10.789s, episode steps: 271, steps per second:  25, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 3483/10000: episode: 15, duration: 9.725s, episode steps: 244, steps per second:  25, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 1.561 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 3657/10000: episode: 16, duration: 6.930s, episode steps: 174, steps per second:  25, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.546 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 3930/10000: episode: 17, duration: 10.842s, episode steps: 273, steps per second:  25, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.487 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 4202/10000: episode: 18, duration: 10.718s, episode steps: 272, steps per second:  25, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.504 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 4475/10000: episode: 19, duration: 10.804s, episode steps: 273, steps per second:  25, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.564 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 4651/10000: episode: 20, duration: 7.016s, episode steps: 176, steps per second:  25, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.443 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 4834/10000: episode: 21, duration: 7.238s, episode steps: 183, steps per second:  25, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.623 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 5050/10000: episode: 22, duration: 8.576s, episode steps: 216, steps per second:  25, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.528 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 5331/10000: episode: 23, duration: 11.159s, episode steps: 281, steps per second:  25, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.381 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 5605/10000: episode: 24, duration: 10.874s, episode steps: 274, steps per second:  25, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.460 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 5884/10000: episode: 25, duration: 11.170s, episode steps: 279, steps per second:  25, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.441 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 6174/10000: episode: 26, duration: 11.532s, episode steps: 290, steps per second:  25, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.424 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 6485/10000: episode: 27, duration: 12.435s, episode steps: 311, steps per second:  25, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 1.559 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 6655/10000: episode: 28, duration: 6.828s, episode steps: 170, steps per second:  25, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.359 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 6924/10000: episode: 29, duration: 10.752s, episode steps: 269, steps per second:  25, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 1.494 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 7271/10000: episode: 30, duration: 13.761s, episode steps: 347, steps per second:  25, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 1.432 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 7466/10000: episode: 31, duration: 7.847s, episode steps: 195, steps per second:  25, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.344 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 7675/10000: episode: 32, duration: 8.339s, episode steps: 209, steps per second:  25, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.431 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 7855/10000: episode: 33, duration: 7.195s, episode steps: 180, steps per second:  25, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.478 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 8100/10000: episode: 34, duration: 9.770s, episode steps: 245, steps per second:  25, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 1.494 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 8313/10000: episode: 35, duration: 8.604s, episode steps: 213, steps per second:  25, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.465 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 8523/10000: episode: 36, duration: 8.332s, episode steps: 210, steps per second:  25, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.433 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 8719/10000: episode: 37, duration: 7.831s, episode steps: 196, steps per second:  25, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.434 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 8962/10000: episode: 38, duration: 9.736s, episode steps: 243, steps per second:  25, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 1.523 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 9132/10000: episode: 39, duration: 6.922s, episode steps: 170, steps per second:  25, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.471 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 9440/10000: episode: 40, duration: 12.506s, episode steps: 308, steps per second:  25, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 1.536 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 9614/10000: episode: 41, duration: 6.984s, episode steps: 174, steps per second:  25, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.420 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 9794/10000: episode: 42, duration: 7.230s, episode steps: 180, steps per second:  25, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.383 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "done, took 403.723 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0205d20550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n69KJdTnWJE",
        "outputId": "cd4f7cba-937f-4998-ba92-b73bca948890"
      },
      "source": [
        "agent.save_weights('policy.h5', overwrite=True)\n",
        "agent.test(env, nb_episodes=10, visualize=False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing for 10 episodes ...\n",
            "Episode 1: reward: 0.000, steps: 10000\n",
            "Episode 2: reward: 0.000, steps: 10000\n",
            "Episode 3: reward: 0.000, steps: 10000\n",
            "Episode 4: reward: 0.000, steps: 10000\n",
            "Episode 5: reward: 0.000, steps: 10000\n",
            "Episode 6: reward: 0.000, steps: 10000\n",
            "Episode 7: reward: 0.000, steps: 10000\n",
            "Episode 8: reward: 0.000, steps: 10000\n",
            "Episode 9: reward: 0.000, steps: 10000\n",
            "Episode 10: reward: 0.000, steps: 10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f02057d2710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}